{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70674a85-c044-421c-a058-259fe3355834",
   "metadata": {},
   "source": [
    "# LM-Infinite: Zero-Shot Extreme Length Generalization for Large Language Models [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8c5a1c-85d1-4da2-b001-570be96e6f5a",
   "metadata": {},
   "source": [
    "## Motiváció\n",
    "\n",
    "A nagy nyelvi modellek általában rövid szövegrészleteken vannak betanítva, a Transformer architektúra négyzetes komplexitása miatt. Ennek következtében teljesítményük drasztikusan romlik, ha a bemenet hosszabb, mint amivel a tanítás során találkoztak.\n",
    "\n",
    "Ez súlyosan korlátozza a gyakorlati alkalmazásokat, amelyek hosszú kontextust igényelnek, példaul:\n",
    "\n",
    "- tudományos cikkek feldolgozása,\n",
    "- forráskódok elemzése,\n",
    "- hosszú párbeszédek kezelése.\n",
    "\n",
    "A szerzők elemzéssel és emprikus vizsgálatokkal három fő tényezőt azonosítanak, amelyek a hosszú kontextusra való általánosítás sikertelenségét okozzák. A korábban használt technikák - például a figyelmi ablak csonkolása vagy a relatív pozíciós kódolás - nem alkalmazhatóak előretanított modellekre, finomhangolás nélkül.\n",
    "\n",
    "Ezekre a kihíváokra válaszul a szerzők az LM-Infinite módszert javasolják, amely egyszerű és hatékony megoldást nyújt. A módszer paraméter-frissítés nélkül működik, és lehetővé teszi, hogy a 2000 vagy 4000 hosszúságu szakaszokon betanított LLM-ek akár 200 millió token hosszú bemenetekre is általánosítsanak, miközben megőrzik a perplexitásukat és a generálási minőségüket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0af163-1264-4a02-ab9b-0a0b2ad17677",
   "metadata": {},
   "source": [
    "## Miért nem általánosítanak az LLM-ek hosszú kontextusra?\n",
    "\n",
    "A szerzők három fő tényezőt azonosítottak, amelyek miatt a Transformer-alapú nyelvi modellek nem képesek a tanítási szekvenciahosszon túli bemeneteket megfelelően kezelni.\n",
    "\n",
    "### Nem látott távolságok a tokenek között\n",
    "\n",
    "A relatív pozíciós kódolást használó modellekben két token közötti figyelem súlya a relatív távolságuktól függ. Ha a szekvencia hosszabb, mint a tanítási időben látott maximális hossz, akkor olyan távolságértékek is megjelenhetnek, amelyekkel a modell so.sem találkozott.\n",
    "\n",
    "Ez a probléma azért jelentkezik, mert a pozíciós beágyazások a tanítási tartományon kívüli értékekre való extrapolációja instabil lehet. A szerzők megfigyelték, hogy ezek a nem látott távolságok a figyelem logitjeinek \"robbanását\" okozhatják, ami a modell teljesítményének drasztikus romlásához vezet.\n",
    "\n",
    "Például, ha egy modell legfeljebb 4096 token hosszú szekvenciákon volt tanítva, akkor a 4096-nál nagyobb relatív távolságok nem látható értékeknek számítanak, és a modell nem tudja, hogyan kezelje ezeket.\n",
    "\n",
    "### Nem látott tokenszám\n",
    "\n",
    "Hosszabb szekvenciák esetén a tokeneknek tübb más tokenre kell figyelmüket osztaniuk. A figyelem mechanizmus softmax normalizációja miatt, ha több token verseng a figyelemért, az egyes tokenekre jutó figyelemsúlyok kisebbek lesznek, és az eloszlás \"szétterül\".\n",
    "\n",
    "A probléma az, hogy a modell tanítása során sosem látott ennyi együtthatót a softmac normalizációban. A szerzők megfigyelték, hogy ez a figyelem entrópiájának a tanítási tartományon túli növekedést okozhatja - azaz a figyelmi eloszlás túl egyenletessé váluk, és a modell nehezen különbözteti meg a fontos és kevésbé fontos tokeneket.\n",
    "\n",
    "Ez különösen a későbbi pozíciókban lévő tokeneket érinti, amelyeknek a teljes hosszú kontextusra kell figyelnüik.\n",
    "\n",
    "### A kezdeti tokenek különleges szerepe\n",
    "\n",
    "A szerzők megfigyelték, hogy a szekvencia elején lévő tokenek más statisztikai helyzetben vannak, mint a többi token:\n",
    "\n",
    "- Mindig jelen vannak, bármilyen hosszú is a szekvencia.\n",
    "- Minden későbbi token számára ezek a legmesszebb lévő tokenek.\n",
    "- A figurájuk a teljes kontextusban állandó, míg a többi token pozíciója változik.\n",
    "\n",
    "Ezért a kezdeti tokenek a figyelem szempontjából egyfajta \"horgonyként\" működnek. Ha ezeket a tokeneket eldobjuk - például egy sliding window megközelítésben - a teljesítmény jelentősen romlik.\n",
    "\n",
    "A szerzők ezt empirikusan is igazolták: amikor a kezdeti tokeneket kizárják a figyelemből, a modell perplexitása drasztikusan megnő, még akkor is, ha egyébként elegendő lokális kontextust adunk neki."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce28cda-6392-4e8e-842c-0ada5106d617",
   "metadata": {},
   "source": [
    "## Hivatkozások\n",
    "\n",
    "1. Chi Han, Qifan Wang, Hao Peng, Wenhan Xiong, Yu Chen, Heng Ji, Sinong Wang. LM-Infinite: Zero-Shot Extreme Length Generalization for Large Language Models. June 2024. https://doi.org/10.48550/arXiv.2308.16137"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.14.2 (~/Work/ai_notebooks/.venv)",
   "language": "python",
   "name": "ai_notebooks_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
